# Projeto Spark - GeraÃ§Ã£o e Tratamento de Dados GA4

Este projeto tem como objetivo **gerar dados sintÃ©ticos** semelhantes ao Google Analytics 4 (GA4) utilizando a biblioteca [Faker](https://faker.readthedocs.io/), exportando-os em diferentes formatos (Parquet, CSV e XLSX).  
Posteriormente, os dados serÃ£o **tratados e padronizados utilizando o Apache Spark localmente**, simulando cenÃ¡rios de ETL com dados "sujos" (valores nulos, schemas divergentes e fontes parciais).

---

## ğŸ“‚ Estrutura do Projeto
```
Projeto-Spark/
â”‚
â”œâ”€â”€ generator/ # CÃ³digo Python para geraÃ§Ã£o dos dados
â”‚ â”œâ”€â”€ generate_data.py
â”‚ â””â”€â”€ config/
â”‚ â””â”€â”€ settings.py
â”‚
â”œâ”€â”€ logs/ # SaÃ­da de logs de execuÃ§Ã£o
â”‚ â””â”€â”€ ga4_generator.log
â”‚
â”œâ”€â”€ data/ # Pasta de dados brutos (Raw)
â”‚ â”œâ”€â”€ parquet/
â”‚ â”œâ”€â”€ csv/
â”‚ â””â”€â”€ xlsx/
â”‚
â”œâ”€â”€ .venv/ # Ambiente virtual (Python)
â”œâ”€â”€ generator.ps1 # Script PowerShell para execuÃ§Ã£o no Windows
â””â”€â”€ README.md
```

---

## âš™ï¸ Ambiente Virtual (Windows)

O projeto utiliza uma **virtual environment (venv)** para isolar as dependÃªncias.  
Siga os passos abaixo para criar e ativar:

### 1. Criar a venv
No diretÃ³rio raiz do projeto, execute:

```powershell
python -m venv .venv

2. Ativar a venv

No PowerShell (Windows):

. .\.venv\Scripts\Activate.ps1

VocÃª verÃ¡ o prefixo (.venv) no terminal, indicando que o ambiente estÃ¡ ativo.

3. Instalar as dependÃªncias

Com a venv ativada, instale os pacotes:

pip install -r requirements.txt
```
---

## ğŸ”¥ Tratamento com Spark Local

ApÃ³s a geraÃ§Ã£o, os arquivos ficam disponÃ­veis na pasta data/.
O prÃ³ximo passo serÃ¡ o tratamento e padronizaÃ§Ã£o com Apache Spark localmente:

Leitura de mÃºltiplos formatos (.parquet, .csv, .xlsx).

PadronizaÃ§Ã£o de schemas (resolvendo nomes alternativos de colunas).

Tratamento de valores nulos.

CriaÃ§Ã£o de camadas Bronze / Silver / Gold no processo de ETL.

O Spark serÃ¡ configurado em ambiente local (via Docker ou instalaÃ§Ã£o direta) para simular pipelines de dados reais.

## ğŸ“Œ Tecnologias Utilizadas

Python 3.10+

Faker (geraÃ§Ã£o de dados sintÃ©ticos)

Pandas (manipulaÃ§Ã£o e exportaÃ§Ã£o de dados)

Apache Spark (local) (tratamento, padronizaÃ§Ã£o e ETL)

PowerShell (automatizaÃ§Ã£o no Windows)